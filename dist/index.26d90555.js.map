{"mappings":"AAAA,sCAAsC;AAEtC,sBAAsB;AACtB,uBAAuB;AACvB,mDAAmD;AACnD,uCAAuC;AACvC,wBAAwB;AACxB,0BAA0B;AAC1B,gBAAgB;AAChB,oBAAoB;AAEpB,8BAA8B;AAC9B,yEAAyE;AACzE,IAAI;AAEJ,8BAA8B;AAC9B,gDAAgD;AAChD,qCAAqC;AACrC,2BAA2B;AAC3B,yCAAyC;AACzC,0CAA0C;AAC1C,6DAA6D;AAC7D,8BAA8B;AAC9B,uCAAuC;AACvC,+BAA+B;AAC/B,mCAAmC;AACnC,4CAA4C;AAC5C,+CAA+C;AAC/C,mDAAmD;AACnD,wDAAwD;AACxD,4BAA4B;AAC5B,kCAAkC;AAClC,IAAI;AAEJ,oCAAoC;AACpC,oDAAoD;AACpD,8CAA8C;AAC9C,qEAAqE;AACrE,gCAAgC;AAChC,wCAAwC;AACxC,oCAAoC;AACpC,wBAAwB;AACxB,iCAAiC;AACjC,qBAAqB;AACrB,6CAA6C;AAC7C,eAAe;AACf,oCAAoC;AACpC,4BAA4B;AAC5B,kCAAkC;AAClC,wBAAwB;AACxB,qBAAqB;AACrB,0BAA0B;AAC1B,eAAe;AACf,0BAA0B;AAC1B,QAAQ;AACR,uBAAuB;AACvB,QAAQ;AAER,kBAAkB;AAElB,uCAAuC;AACvC,yDAAyD;AACzD,IAAI;AAEJ,0CAA0C;AAC1C,2DAA2D;AAC3D,kDAAkD;AAClD,gCAAgC;AAChC,mDAAmD;AACnD,eAAe;AACf,sCAAsC;AACtC,kBAAkB;AAClB,oCAAoC;AACpC,iEAAiE;AACjE,gDAAgD;AAChD,8CAA8C;AAC9C,2CAA2C;AAC3C,6CAA6C;AAC7C,gEAAgE;AAChE,yBAAyB;AACzB,QAAQ;AAER,+DAA+D;AAC/D,IAAI;AAEJ,cAAc","sources":["sound.js"],"sourcesContent":["// import { hslToRgb } from './utils';\n\n// const WIDTH = 1500;\n// const HEIGHT = 1500;\n// const canvas = document.querySelector('canvas');\n// const ctx = canvas.getContext('2d');\n// canvas.width = WIDTH;\n// canvas.height = HEIGHT;\n// let analyzer;\n// let bufferLength;\n\n// function handleError(err) {\n//   console.log('You must give access to your mic in order to proceed');\n// }\n\n// async function getAudio() {\n//   const stream = await navigator.mediaDevices\n//     .getUserMedia({ audio: true })\n//     .catch(handleError);\n//   const audioCtx = new AudioContext();\n//   analyzer = audioCtx.createAnalyser();\n//   const source = audioCtx.createMediaStreamSource(stream);\n//   source.connect(analyzer);\n//   // How much data should we collect\n//   analyzer.fftSize = 2 ** 8;\n//   // pull the data off the audio\n//   // how many pieces of data are there?!?\n//   bufferLength = analyzer.frequencyBinCount;\n//   const timeData = new Uint8Array(bufferLength);\n//   const frequencyData = new Uint8Array(bufferLength);\n//   drawTimeData(timeData);\n//   drawFrequency(frequencyData);\n// }\n\n// function drawTimeData(timeData) {\n//   // inject the time data into our timeData array\n//   analyzer.getByteTimeDomainData(timeData);\n//   // now that we have the data, lets turn it into something visual\n//   // 1. Clear the canvas TODO\n//   ctx.clearRect(0, 0, WIDTH, HEIGHT);\n//   // 2. setup some canvas drawing\n//   ctx.lineWidth = 10;\n//   ctx.strokeStyle = '#ffc600';\n//   ctx.beginPath();\n//   const sliceWidth = WIDTH / bufferLength;\n//   let x = 0;\n//   timeData.forEach((data, i) => {\n//     const v = data / 128;\n//     const y = (v * HEIGHT) / 2;\n//     // draw our lines\n//     if (i === 0) {\n//       ctx.moveTo(x, y);\n//     } else {\n//       ctx.lineTo(x, y);\n//     }\n//     x += sliceWidth;\n//   });\n\n//   ctx.stroke();\n\n//   // call itself as soon as possible\n//   requestAnimationFrame(() => drawTimeData(timeData));\n// }\n\n// function drawFrequency(frequencyData) {\n//   // get the frequency data into our frequencyData array\n//   analyzer.getByteFrequencyData(frequencyData);\n//   // figure out the bar width\n//   const barWidth = (WIDTH / bufferLength) * 2.5;\n//   let x = 0;\n//   frequencyData.forEach(amount => {\n//     // 0 to 255\n//     const percent = amount / 255;\n//     const [h, s, l] = [360 / (percent * 360) - 0.5, 0.8, 0.5];\n//     const barHeight = HEIGHT * percent * 0.5;\n//     // TODO: Convert the colour to HSL TODO\n//     const [r, g, b] = hslToRgb(h, s, l);\n//     ctx.fillStyle = `rgb(${r},${g},${b})`;\n//     ctx.fillRect(x, HEIGHT - barHeight, barWidth, barHeight);\n//     x += barWidth + 2;\n//   });\n\n//   requestAnimationFrame(() => drawFrequency(frequencyData));\n// }\n\n// getAudio();\n"],"names":[],"version":3,"file":"index.26d90555.js.map","sourceRoot":"/__parcel_source_root/"}